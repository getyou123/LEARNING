## 当谈论大数据的时候我们在谈论什么
  
- 大数据定义：IBM中的3V 和 4V；IDC中的新的技术架构，这种架构中的数据的高速流动和数据分析和挖掘等
- 技术范型转化： 传统互联网和商业数据采用的是 传统的关系型数据库 => 
    - hadoop
    - nosql ： 不单纯追求应用场景的统一，针对不同的应用场合有不同的解决方案
      - 社交网络使用图数据库
      - 实时性高的使用hbase等
    - 应用场景进一步推动了技术转型：
      - 数据存储
      - 数据基本处理
      - 数据挖掘与分析
      - 数据可视化
      - 主要目标是浪里淘金，获取知识
    - 大数据技术的子领域：
      - ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301300917236.png)

## 数据分片和路由
- 数据分片产生的原因： 数据量级的进化导致的传统的纵向扩展（不增加机器，提高单机性能，让单机具有更强的数据存储和数据处理能力）并不能满足大数据的挑战，所以更合适的横向扩展（增加机器）并提供数据分片，这些分片分别存储在机器上
- 数据路由：如何找到这些分片在哪个位置哪个机器上呢？ 这个问题称为数据路由
- 数据复制：在分片基数上增加副本机制，提高可用性
- 数据复制和数据分片的关系：![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301300931517.png)
- 数据复制带来的问题：高可用满足了，但是如何保证多个副本之间的数据是一致的呢？

#### 数据分片和路由通用的抽象模型
- 其实就是两级映射关系
  - 第一级是文件记录=>分片的，也就是key-partition映射，这里是一对一的映射关系，按照key对数据进行水平的切分
  - 第二级是分片到机器的映射，一般是多对一的映射关系，一个机器上存储多个分片数据
  - 映射模型如图：![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301301521386.png)
  - 哈希分片和范围分片：
    - hash支持点查 Point Query 常见的k-v的都是支持点查的
    - 范围及支持点查，也支持范围查询 Range Query
  
#### 哈希分片 Hash Partition
- Round Robin 方式：
  - 最最简单取模的运算：![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301301529193.png)
  - 这种方式的优点在于简单，缺点在于如果新加一个机器的话，就会导致K=>k+1,这样之前的key-partition关系就失效了，只能进行重新分配
  - 缺点主要在机器数K的强耦合性 ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301301542367.png)
- 虚拟桶 Virtual Buckets
  - 运行机制如下：![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301301548310.png) 这里现实的额key虽然是顺序，但是其实是不影响的
  - 就是引入了虚拟桶的概念，key-> Virtual Bucket 使用hash方式，多条记录可能落在一个桶上
  - 然后从Virtual Buckets -> 实际的物理机器是按照查表的方式来操作的
  - 这样情况下增加机器只是在Virtual Buckets 和 实际机器的查找表中增加了表项，而不会导致原来的对应关系失效
  - 这里就体现了解耦操作，增加了灵活性
  
### 一致性hash
- 分布式哈希表DHT，这是hash表的分布式扩展，即考虑了每台机器都是负责了一部分数据存储的情况下的，如果对数据进行增删改查
- ***一致性hash是DHT的一种实现方式*** 其核心就是建立数据到机器的映射关系，实现***无论数据请求打在哪台机器上都可以正确响应这个请求***
- 基于p2p的网络结构
- 主要思想描述：
  - 环形的hash地址空间：地址长度为m时候，hash内地址取值范围为[0-2^m-1],如果是5的话，那么地址范围是0-31 ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301311011723.png)
  - 将机器hash到地址环上：最简单的方式就是端口+ip地址进行hash，但是无法保证机器的负载相对均衡 ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301311015328.png)
  - 将数据hash到地址环上：也是按照hash函数对数据进行映射 ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301311019936.png)
  - 机器存储哪些数据呢？顺时针转动这个环，让数据直接落在节点上，这个就是对应的机器应该是存储的数据key的范围
  - 如何实现数据路由？给定的数据，hash获取到key，然后看当前的数据打在哪个机器上，这个机器首先查是不是自己存储的，如果不命中，那么就发送请求去找其他节点去查找（可能多次，不过对于被请求的首节点来说是发送给其他机器一次，收到其他机器回复一次），查找成功之后返回给请求方，这里描述了一次可能请求和查找过程  <div align="left"> <img src="https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301311036241.png" /> </div> 
  - 数据路由中如何从当前不命中机器A尽快的找到实际持有数据的target机器X呢？ eg情况是 key = 24 ， 机器A命中范围是(10-20]，实际就是要查找持有key=24的机器
    - 最基本的方法是 顺时针的一个一个的节点遍历,看哪个机器的信息中包括key = 24
    - 上面的方式的查找效率并不是很高，可以在每个机器配置指定距离的落点情况，即![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301311105650.png)，这样可以加快查找效率
  - 如果集群新增了节点的话：
    - 新增机器的key插入到环中，然后还是按照顺时针的顺序存储某个key范围内的数据，按照这个标准来进行调整
    - 同时注意更新相应的节点的路由表
  - 如果集群删除了节点的话
    - 实际地址空间就会少了一个key，然后删除机器的本来存储的数据直接向后落到后面一个节点即可，比Round Robin好多了
  - 上述算法的问题点-未考虑到机器的异质性
    - 就是加一层的思想，加一层虚拟节点，让每个物理机器映射为不同个数的虚拟节点参与撒花姑娘书的
    - 不同机器按照其性能配置，配置高的多几个虚拟节点，配置低的少一些虚拟节点
  - 上述算法的问题点-雪崩的可能性
    - 删除一个节点之后数据顺移到下一个节点，下一个节点如果也顶不住
  
### 范围分片 Range Partition
- 所有记录按照主键排序，然后主键空间进行按照范围进行分片，每个分片内也是有序的，记录一个最新key值和机器映射 ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301311124080.png)


## 数据复制和一致性
### 基本原则和设计理念

#### CAP理论
- Consistency 强一致性：多个副本和单份数据的效果是一样的
- Availability 可用性：客户端对于系统的读写都可以在限定的时延内完成
- Partition Tolerance 分区容忍性：因为网络等原因，某个分区的机器可能不可用，这种情况还是需要能继续工作
- 一般来说必须要是需要满足p的，P是不可避免的必须要满足的，要么是AP 要么是 CP；即要么是强一致减弱可用性，要么是弱一致性强可用性；

#### ACID原则（这个是数据库的采用的原则）
- Atomicity 原子性，要么操作全部完成，要么都失败
- Consistency 一致性，事务开始和结束时候，系统的一致性没有被破坏，这个区别于CAP原则中的C，虽然两者都是数据一致性的定义，但是两者的含义是不同的
- Isolation 隔离，事务的隔离性是指一个事务的执行不能被其他事务干扰，即一个 事务内部的操作及使用的数据对并发的其他事务是隔离的，并发 执行的各个事务之间不能互相干扰。 ---并发的事务互不影响
- Durability 持久性，事务更新了数据库的状态之后，这个更新和改变是持久的，不会无缘无故的回滚

#### BASE原则（云存储和nosql）
- 基于CAP理论，核心思想就是即使无法做到强一致性，那就按照实际的业务特点，采用不同的方法到达最终一致性
- Basically Available（基本可用），主要损失在下面两个部分
  - 响应时间上的损失
  - 功能损失（业务上暂时搞个页面代替着）

- Soft state（软状态）

- Eventually consistent（最终一致性）
  - 一致性的概念 ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301311559546.png)
  - 最终一致性： 经过一段时间的同步之后，所有副本的数据达到一致性的状态，不需要实时的保证一致性![不一致窗口的示意图，即数据不一致的窗口](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202301311542980.png)
  - 最终一致性的变种为
    - 因果一致性：A写然后让B读，B应该是能读出来A的写，则称A和B保持了因果一致性
    - 读己之所写：A写然后A读到前面A写的数据，称为读己之所写
    - 会话一致性：一个会话能保持的 读己之所写
    - 单调读一致性：A读取的数据状态V2，那么之后的读取数据不会比V2更前的
    - 单调写一致性：A写数据数据状态V2，之后的写都是V2之后

### 副本更新策略
- 主要是处理副本之间的数据可能存在的一致性问题
- ①同时更新 不存在主-从副本之区别，所有节点一视同仁，按理来说读的话不需要区分节点，直接去读取就可，下面只考虑写
  - 类型A 不存在一致性协议，分别去响应两个请求，这种不保证两个请求的先后顺序，写请求尤其有风险
  - 类型B 使用某种一致性协议，使得两个请求有先有后的响应，但是这样会增加时延
- ②主从式更新
  - 数据存在副本，副本存在主从之分，写操作时候客户端只和主副本进行沟通，然后主副本在决定其他副本的更新顺序
    - 主副本***同步***通知其他副本，其他副本完成之后再通知写入方完成： 这种保证了强一致性，但是有时延
    - 主副本异步通知其他副本
    - 混合方式： 写请求来了，主节点同步写入部分副本，其他副本使用异步的方式来（kafka维护消息的一致性的时候就是这样的）
- ③任意节点更新
  - 类似主从方式，但是不固定主节点

### 一致性协议
#### 两阶段提交 2PC
- 用于解决分布式事务问题，实现的是ACID中的A
- 2PC语境下，存在两个实体 协调者 和 参与者
- 也将提交过程分为两个阶段： 表决阶段 和 提交阶段