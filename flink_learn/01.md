###  flink的训练项目

https://github.com/apache/flink-training.git

### 包结构说明&背景说明

- [entity](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fentity) 实体类类型（主要是费用、驾驶事件 两者的关联实体类）
  - 出租车车程(taxi ride)事件结构[TaxiRide.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fentity%2FTaxiRide.java) 一个业务上的车程对应两个事件，里面有个字段来表示是开始还是结束的事件
  - 出租车车费（taxi fare）事件结构 [TaxiFare.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fentity%2FTaxiFare.java)
  - 出租车车费和车程时间关联的结构 [RideAndFare.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fentity%2FRideAndFare.java)
- [RideCountExample.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fridecount%2FRideCountExample.java) 进行count，看做是本项目的wordCount
- [source](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fsource) 产生的数据源
- [utils](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Futils) 工具包


### 启动程序 测试环境
- [RideCountExample.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fridecount%2FRideCountExample.java)

### 练习1 过滤流
- [exercise01](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fexercise01)
- DataStream.filter(FilterFunction) 核心是这个
- 可以写一个实现接口然后 `env.addSource(source).filter(new NYCFilter()).addSink(sink);`

``` 
 public static class NYCFilter implements FilterFunction<TaxiRide> {
        @Override
        public boolean filter(TaxiRide taxiRide) {
            return GeoUtils.isInNYC(taxiRide.startLon, taxiRide.startLat)
                    && GeoUtils.isInNYC(taxiRide.endLon, taxiRide.endLat);
        }
 }
```

- 可以继承 RichFilterFunction 这样的可以在open 和close中进行初始化和清理工作

``` 
public class MyFilter extends RichFilterFunction<Integer> {
    @Override
    public boolean filter(Integer value) throws Exception {
        return value % 2 == 0;
    }
}
```

- Lambda 表达式

``` 
DataStream<Integer> stream = env.fromElements(1, 2, 3, 4);
DataStream<Integer> filtered = stream.filter(value -> value % 2 == 0);
```



### 如何构造一个产出指定类型的Source源
- [TaxiRideGenerator.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fsource%2FTaxiRideGenerator.java)
- 这里用到了自己指定的乱序操作

### 在编写job时候如何更好的切换测试和线上呢？

- 保留job中的source sink，然后new RideCleansingExercise时候来指定具体的sink 和 source
- 重写 RideCleansingExercise 中的 execute方法，代替env的
- [RideCleansingExercise.java](src%2Fmain%2Fjava%2Forg%2Fexample%2FexerciseOne%2FRideCleansingExercise.java)
  这个封装的就很好，整个计算图中的source和sink都是构造实例时候传进来的，然后在调用具体的run方法

### 如何在测试过程中构造一个并行发送数据的source？

- 参考 [ParallelTestSource.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FParallelTestSource.java)，注意这里是子任务的概念和数组下标的对应方式

``` 
        TaxiRide toThePole = testRide(-73.9947F, 40.750626F, 0, 90);
        TaxiRide fromThePole = testRide(0, 90, -73.9947F, 40.750626F);
        TaxiRide atPennStation = testRide(-73.9947F, 40.750626F, -73.9947F, 40.750626F);
        TaxiRide atNorthPole = testRide(0, 90, 0, 90);

        // 这里构造了可以发送任何数据一个source，直接构造数据然后加入就可以获取到source
        ParallelTestSource<TaxiRide> source = new ParallelTestSource<>(toThePole, fromThePole, atPennStation, atNorthPole);
```

---

### 练习二 有状态的增强(车程及车费)
- [exercise02](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fexercise02)
- 背景主要为了实现一个开始的车程TaxiRide和车费TaxiFare进行匹配，构造产出一个车程车费对象RideAndFare
- 这里假设了 START 和 fare 事件完美配对
- [RidesAndFaresExercise.java](src%2Fmain%2Fjava%2Forg%2Fexample%2FexerciseTwo%2FRidesAndFaresExercise.java)
- [RidesAndFaresExerciseTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FRidesAndFaresExerciseTest.java)

### 如何理解keyedStream

- 调用 keyBy(KeySelector) 实现，Key selector 函数接收单条记录作为输入，返回这条记录的 key。该 key
  可以为任何类型，但是它的计算产生方式必须是具备确定性的
- Key 是"虚拟" 的。它们定义为基于实际数据的函数，用以操纵分组算子。 所以实际上不是把数据类型转为key-value形式
- 数据还是整条的流，而且 KeyedStream<WaterSensor, String> 这个类型表示的流中的数据类型是WaterSensor，然后keyed的数据类型是String，即WaterSensor数据流按照String类型的id进行分组


### 关于flink的state
主要分为
1. managed state
  - 算子状态
  - Keyed DataStream：作用在指定的key上，
  - 广播状态
2. raw state


### flink中的Keyed State

keyed state 接口提供不同类型状态的访问接口，这些状态都作用于当前输入数据的 key 下。换句话说，这些状态仅可在 KeyedStream
上使用，在Java/Scala API上可以通过 stream.keyBy(...) 得到 KeyedStream，在Python API上可以通过 stream.key_by(...) 得到
KeyedStream。

接下来，我们会介绍不同类型的状态，然后介绍如何使用他们。所有支持的状态类型如下所示：

* ValueState<T>: 保存一个可以更新和检索的值（如上所述，每个值都对应到当前的输入数据的 key，因此算子接收到的每个 key
  都可能对应一个值）。 这个值可以通过 update(T) 进行更新，通过 T value() 进行检索。

* ListState<T>: 保存一个元素的列表。可以往这个列表中追加数据，并在当前的列表上进行检索。可以通过 add(T) 或者 addAll(
  List<T>) 进行添加元素，通过 Iterable<T> get() 获得整个列表。还可以通过 update(List<T>) 覆盖当前的列表。

* ReducingState<T>: 保存一个单值，表示添加到状态的所有值的聚合。接口与 ListState 类似，但使用 add(T) 增加元素，会使用提供的
  ReduceFunction 进行聚合。

* AggregatingState<IN, OUT>: 保留一个单值，表示添加到状态的所有值的聚合。和 ReducingState 相反的是, 聚合类型可能与
  添加到状态的元素的类型不同。 接口与 ListState 类似，但使用 add(IN) 添加的元素会用指定的 AggregateFunction 进行聚合。

* MapState<UK, UV>: 维护了一个映射列表。 你可以添加键值对到状态中，也可以获得反映当前所有映射的迭代器。使用 put(UK，UV) 或者
  putAll(Map<UK，UV>) 添加映射。 使用 get(UK) 检索特定 key。 使用 entries()，keys() 和 values() 分别检索映射、键和值的可迭代视图。你还可以通过
  isEmpty() 来判断是否包含任何键值对。

所有类型的状态还有一个clear() 方法，清除当前 key 下的状态数据，也就是当前输入元素的 key。

请牢记，这些状态对象仅用于与状态交互。状态本身不一定存储在内存中，还可能在磁盘或其他位置。 另外需要牢记的是从状态中获取的值取决于输入元素所代表的
key。 因此，在不同 key 上调用同一个接口，可能得到不同的值。

你必须创建一个 StateDescriptor，才能得到对应的状态句柄。 这保存了状态名称（正如我们稍后将看到的，你可以创建多个状态，并且它们必须具有唯一的名称以便可以引用它们），
状态所持有值的类型，并且可能包含用户指定的函数，例如ReduceFunction。
根据不同的状态类型，可以创建ValueStateDescriptor，ListStateDescriptor， AggregatingStateDescriptor, ReducingStateDescriptor
或 MapStateDescriptor。

状态通过 RuntimeContext 进行访问，因此只能在 rich functions 中使用。请参阅这里获取相关信息， 但是我们很快也会看到一个例子。RichFunction
中 RuntimeContext 提供如下方法：

* ValueState<T> getState(ValueStateDescriptor<T>)
* ReducingState<T> getReducingState(ReducingStateDescriptor<T>)
* ListState<T> getListState(ListStateDescriptor<T>)
* AggregatingState<IN, OUT> getAggregatingState(AggregatingStateDescriptor<IN, ACC, OUT>)
* MapState<UK, UV> getMapState(MapStateDescriptor<UK, UV>)

示例程序：

- [CountWindowAverage.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2FStateLearn%2FCountWindowAverage.java)
- [AvgByKeyedStateTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FAvgByKeyedStateTest.java)

### flink中的状态的有效期 TTL

任何类型的 keyed state 都可以有 有效期 (TTL)。如果配置了 TTL 且状态值已过期，则会尽最大可能清除对应的值，这会在后面详述。

所有状态类型都支持单元素的 TTL。 这意味着列表元素和映射元素将独立到期。

在使用状态 TTL 前，需要先构建一个StateTtlConfig 配置对象。 然后把配置传递到 state descriptor 中启用 TTL 功能。

```
import org.apache.flink.api.common.state.StateTtlConfig;
import org.apache.flink.api.common.state.ValueStateDescriptor;
import org.apache.flink.api.common.time.Time;

StateTtlConfig ttlConfig = StateTtlConfig
    .newBuilder(Time.seconds(1)) // 主要是时间是必选的
    .disableCleanupInBackground() // 可以开启 后台线程的清理
    //.cleanupFullSnapshot() 快照是开启清理
    .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)
    .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)
    .build();
    
ValueStateDescriptor<String> stateDescriptor = new ValueStateDescriptor<>("text state", String.class);
stateDescriptor.enableTimeToLive(ttlConfig);
```

过期数据的清理：

- 全量快照时进行清理 .cleanupFullSnapshot()
- 增量数据清理 .cleanupIncrementally(10, true)
- 在 RocksDB 压缩时清 .cleanupInRocksdbCompactFilter(1000)

### 算子状态 (Operator State)

算子状态（或者非 keyed 状态）是绑定到一个并行算子实例的状态。Kafka Connector 是 Flink 中使用算子状态一个很具有启发性的例子。Kafka
consumer 每个并行实例维护了 topic partitions 和偏移量的 map 作为它的算子状态。

当并行度改变的时候，算子状态支持将状态重新分发给各并行算子实例。处理重分发过程有多种不同的方案。

在典型的有状态 Flink 应用中你无需使用算子状态。它大都作为一种特殊类型的状态使用。用于实现 source/sink，以及无法对 state
进行分区而没有主键的这类场景中。

算子的状态一般都和状态的开始和结束的信号有关。

### 广播状态 (Broadcast State)

广播状态是一种特殊的算子状态。引入它的目的在于支持一个流中的元素需要广播到所有下游任务的使用情形。在这些任务中广播状态用于保持所有子任务状态相同。
该状态接下来可在第二个处理记录的数据流中访问。可以设想包含了一系列用于处理其他流中元素规则的低吞吐量数据流，这个例子自然而然地运用了广播状态。
考虑到上述这类使用情形，广播状态和其他算子状态的不同之处在于：

它具有 map 格式，
它仅在一些特殊的算子中可用。这些算子的输入为一个广播数据流和非广播数据流，
这类算子可以拥有不同命名的多个广播状态 。

- 一种情况是：一个规则流和一条应用这些规则的事件流，[BroadcastStateFunction.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fstreaming_with_flink%2Fchapter7%2FBroadcastStateFunction.java)
  使用广播流动态配置阈值的温度报警应用，核心是KeyedBroadcastProcessFunction既处理广播流又处理key流，然后广播流还是更新的



---

## 练习三 窗口分析 (每小时小费)

- 确定每小时赚取最多小费的司机，从 TaxiFare 流中按照窗口进行统计
- 所希望的结果是每小时产生一个 Tuple3<Long, Long, Float> 记录的数据流。 这个记录（Tuple3<Long, Long, Float>
  ）应包含该小时结束时的时间戳（对应三元组的第一个元素）、 该小时内获得小费最多的司机的
  driverId（对应三元组的第二个元素）以及他的实际小费总数（对应三元组的第三个元素））。
- 流转流的结构： 先开窗，然后按照司机id进行聚合，之后这个流在转为从每个司机流中获取最大的

### 误区排查

- 第一步都是按照小时进行开窗，计算窗内（不看前一个窗口）存在tips的driverId，然后数据输出的量级是：窗口内有driverId的计算窗口内的和

``` 
        // 构造的输入数据
        TaxiFare oneFor1In1 = testFare(1, t(0), 1.0F);
        TaxiFare fiveFor1In1 = testFare(1, t(15), 5.0F);
        ----
        TaxiFare tenFor1In2 = testFare(1, t(90), 10.0F);
        TaxiFare twentyFor2In2 = testFare(2, t(90), 20.0F);
        TaxiFare zeroFor3In2 = testFare(3, t(70), 0.0F);
        TaxiFare zeroFor4In2 = testFare(4, t(70), 0.0F);
        TaxiFare oneFor4In2 = testFare(4, t(80), 1.0F);
        TaxiFare tenFor5In2 = testFare(5, t(100), 10.0F);
        
       // 得到的数据输出是，这个是程序外面的时间线无关，因为是按照数据中事件时间算的
        (1577883600000,1,6.0), 
        ----
        (1577887200000,5,10.0), 
        (1577887200000,4,1.0), 
        (1577887200000,3,0.0), 
        (1577887200000,2,20.0), 
        (1577887200000,1,10.0) -- 这里没有driverId = 1 的数据因为上面窗口内没有这个数据
      
```

- 在获取到每个小时内每个司机的sum之后，接下来是需要注意的地方

``` 
  // find the driver with the highest sum of tips for each hour
        DataStream<Tuple3<Long, Long, Float>> hourlyMax =
                hourlyTips.windowAll(TumblingEventTimeWindows.of(Time.hours(1))).maxBy(2);

  -- 因为是开窗的操作，所以还是按照一个窗口内的输出一个 
   [(1577883600000,1,6.0), (1577887200000,2,20.0)]
   
   如果按照
   DataStream<Tuple3<Long, Long, Float>> hourlyMax = hourlyTips
    .keyBy(t -> t.f0)
    .maxBy(2);
    
    这个逻辑来写的话，那就会导致数据的输出是这样的
    (1577883600000,1,6.0), 
    (1577887200000,5,10.0), 
    (1577887200000,5,10.0), 
    (1577887200000,5,10.0), 
    (1577887200000,2,20.0), 
    (1577887200000,2,20.0)]
    可以看到是上游hourlyTips的每条记录都产出了一条记录，而不是两条记录
```

### 如何设置flink中的水印和时间戳呢？生成水位线？水位线的生成？时间戳的分配？分配时间戳？提取时间戳？

- 一般来说，实际时间戳来自数据中的某个字段，使用TimestampAssigner去设置
- 同时时间戳的分配与 watermark 的生成是齐头并进的，水印用来告知flink程序的时间进度，使用 WatermarkGenerator 来设置
- `WatermarkStrategy` 工具类整合了 `TimestampAssigner` 和 `WatermarkGenerator` ，在source时候直接设置获取水印和时间戳

``` 
WatermarkStrategy<TaxiRide> watermarkStrategy =
                WatermarkStrategy.<TaxiRide>forBoundedOutOfOrderness(Duration.ofSeconds(60))
                        .withTimestampAssigner(
                                (ride, streamRecordTimestamp) -> ride.getEventTimeMillis());

        // create the pipeline
        rides.assignTimestampsAndWatermarks(watermarkStrategy)
```
### flink的系统架构？
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072317579.png)
主要包含：jobmanager taskmanager 然后进一步的细分为 jobmanager dispatcher Resourcemanager slot 等组件 


### flink on yarn 是如何提交的？提交过程是啥样的？（per-job）
- https://mdnice.com/writing/a31775688d1e400987493916376ca51f


### flink中任务是如何划分到taskmanger上的？实例化之后的subtask是如何分配到taskmanger上的？
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072321010.png)  
这里的taskmanger上就需要四个线程


### flink的taskmanger之间的数据传输是如何做的？
- 计算图中的实例化的算子，执行的位置在taskmanger中的slot中，但是数据大概率是不会在一个taskmanger中就可完成所有的数据交换的，多个算子实例是分布在不同的taskmanager中的，数据的交换依赖Taskmanger这个JVM进程去使用所在机器的网卡进行。
- 算子实例是数据交换的真正的方向，但是大概率需要走taskmanager的网卡
- 数据的交换，最小的单位是按照一批一批的进行，也是放在网卡的缓冲区中进行积累和发送的。
- 每个taskmanger 的网络缓冲区默认：32KB
  不同的taskmanager通信需要走操作系统网络栈  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072324137.png)

### taskmannager进程之间的数据传输的优化有哪些？
- 首先是算子实例都处在一taskmamnager中的，这种的不走网络，直接是在一个进程内进行数据传输
- 在不同的taskmanager的传输
  • 基于信用值的控制，通信双方互相告知各自缓冲区大小
  Taskchain 如果一个算子和下一个算的并行度是一样的，数据通过本地转发  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072325665.png)


### flink中的source如何理解呢？

- 作为数据输入流中的起点
- 其本质就是一个SourceFunction<?>，然后在env中addSource即可
- [Source01Test.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FSource01Test.java) 展示了多个数据源的方式


自定义数据源，自定义source，自定义实现SourceFunction，可以从三个大维度上区分  
- 是否并行版本：
  - 并行版本： 可实例化为多个subtask 
  - 非并行版本：不可实例化为多个task实例
- rich or 非rich版本
  - rich版本： source 支持访问一些状态，然后open 方法
  - 非rich版本： 不访问其他资源
- 是否可重置
  - 可重置source：本身上游的数据源要支持回放，
     socket这种不可，可重置的数据源函数需要实现CheckpointedFunction接口，
     并把所有读取偏移和相关的元数据信息(例如文件路径或分区ID)存入算子列表状态或算子联合列表状态中
  - 不可重置版source

示例：
- [MySource.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FSourceLearn%2FMySource.java) 展示了自定义source的方式，简单的 SourceFunction
- [ParallelTestSource.java](src%2Ftest%2Fjava%2Forg%2Fexample%2Ftool%2FParallelTestSource.java) 展示了自定的rich + 并行的 source
- [ResettableCountSource.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fstreaming_with_flink%2Fchapter8%2FResettableCountSource.java) 展示了可重置版本的source

### flink中的source如何设置并行度呢？

- 如何判定是按照几个并行度去读取数据的呢
- flink中的一个ParallelSourceFunction 可以支持设置并行度
  `DataStream<String> stream = env.addSource(kafkaConsumer).setParallelism(4);`
- [ParallelTestSource.java](src%2Ftest%2Fjava%2Forg%2Fexample%2Ftool%2FParallelTestSource.java) 这个就是一个很好的案例

### 如何理解flink中的map function

- map 算子其实就是需要一个MapFunction，然后按照在多个并行度上启动执行的mapFunction
- 这个map function是一个并行度上执行一个函数，这个是和并行度是绑定的
- 同理的flatmap需要的是一个flatmapFunction，filter需要的是一个filterFunction
- [FlatMapFunctionTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FFlatMapFunctionTest.java)
- [MapFunctionTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FMapFunctionTest.java)

### flink中如何理解并行度和slot

- 每个计算过程为了对付大数据场景，需要把计算逻辑分为多个子任务，比如 map操作，是对于100条数据的处理，分成50条数据一组作为作为一个子task，那么这个任务的并行度就是2
- 实际有多少资源可用是对应的slot，上面的例子中会要求有2个工人去干活，那么实际可以干活的工人不能少于2个
- .setParallelism(4) 就是在任务层面进行划分子任务，当然分配到slot之后可能是在同一个taskmanager上

### 如何理解flink中的connect两个流？connect和 union的区别是啥？

- connect两个流是貌合神离的 DataStream[A], DataStream[B] -> ConnectedStreams[A,B]
- connect两个流中的数据不要求是一样的，数据类型可以是不同的
- [RidesAndFaresExercise.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fexercise02%2FRidesAndFaresExercise.java) 是一个很好的例子
- union中的两个流的数据类型要求是一致的，可以操作多个流进行union

### flink中的简单的滚动算子？

基于KeyedStream流，里面的内容最好是POJO，scala中的case 类，或者元组类型

- sum, 分组求和
- min, 分组求最小值
- max 分组求最大值
- minBy, 分组求组内的最小值的那条记录
- maxBy 分组求最内的最大值的那条记录
- reduce 分组进行组内的reduce方法
- 操作之后的数据类型发生了变化 KeyedStream -> SingleOutputStreamOperator

滚动聚合算子这些算子会为每个处理过的键值维持一个状态，由于这些状态不会自动清理，只能用在有限的key的流上。

### POJO类的定义？

该类型必须是公共类，即必须使用 public 修饰符修饰。
该类型必须具有公共的无参构造函数。
该类型的属性必须是公共属性，即必须使用 public 修饰符修饰，并且必须具有对应的 get/set 方法。

### flink中的min max sum等底层原理？maxBy 和 max啥区别呢？

- [SimpleAgrTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FSimpleAgrTest.java)
- min max这类算子类似mr，分组之后，在局部聚合和全局聚合过程中，Flink 会使用状态管理器来维护中间状态，以支持有状态的计算
- minBy maxBy这些是返回最大值对应的那条记录，而min max等返回的是最大值，这是不同的
- minBy maxBy 支持第二个参数 .maxBy("temperature",true); 同样的最大值保留不保留第一条的作为结果

### flink中的process方法，处理函数，处理函数的分类

- 这个是个比较底层的算子，ProcessFunction 可以访问比较底层的 事件时间，水位线，注册定时器
- 一共有8种process 处理函数：
  - ProcessFunction
  - KeyedProcessFunction
  - CoProcessFunction
  - ProcessJoinFunction
  - BroadcastProcessFunction
  - KeyedBroadcastProcessFunction
  - ProcessWindowFunction
  - ProcessAllWindowFunction
- 针对非keyed 的流： ProcessFunction 中最重要的方法是 processElement，它会在每个输入元素到达时调用，可以对元素进行处理，并输出新的元素或通过
  Output 接口向侧输出流输出元素。
- 针对keyed的流 ；KeyProcessFunction 来处理，可以获取key等操作，主要是processElement 和 OnTimer两个方法，processElement 方法和上面的一样的功能，
OnTimer是注册某个定时器然后，到点之后触发这个定时器

定时器的处理案例：
- [LongRidesExercise.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2Fexercise04%2FLongRidesExercise.java) 长程报警
- [ProcessFunctionTimers.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fstreaming_with_flink%2Fchapter6%2FProcessFunctionTimers.java) 处理上升的温度然后告警

几种常见的窗口处理函数：
- [WindowFunctions.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fstreaming_with_flink%2Fchapter6%2FWindowFunctions.java)  
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405191853496.png)

- 增量聚合函数：（对于进来的数据然后更新窗口中的状态，状态少，数据缓存少）
  - ReduceFunction：输入和输出必须要类型一致
  - AggregateFunction：输入和输出的类型可以不一致
- 全局窗口函数：（缓存了全部数据）
  - ProcessWindowFunction：非增量聚合的类型，接受输入，处理，然后发送结果
- 增量聚合+全局窗口函数：（结合二者的优点）
  - 数据进入时候使用增量聚合，然后聚合完成之后，把聚合之后的一条结果给到ProcessWindowFunction


``` 
Context 对象提供了许多与时间和定时器相关的方法： 

timestamp() 方法可以获取当前元素的时间戳（即事件时间或者处理时间）。

getCurrentKey() 方法可以获取当前元素的键（即分组键）。

timerService().currentProcessingTime() 方法可以获取当前的处理时间。

timerService().currentWatermark() 方法可以获取当前的水位线。

timerService().registerProcessingTimeTimer() 方法可以注册一个处理时间定时器，当处理时间到达指定时间时，会触发 onTimer() 方法。

timerService().registerEventTimeTimer() 方法可以注册一个事件时间定时器，当事件时间到达指定时间时，会触发 onTimer() 方法。

timerService().deleteProcessingTimeTimer() 方法可以删除一个处理时间定时器。

timerService().deleteEventTimeTimer() 方法可以删除一个事件时间定时器。

```

### flink中如何对流进行分区？
- 首先明确分区和分组的概念的不同：
  - 分组是keyBy操作，从一个DateStream转为一个KeyedStream，这描述的是流内的数据被分组
  - 分区是说数据按照某些规则，定好了从上游的subtasks如何发送到下游的subtasks，其实描述的是数据转发分发的策略
- keyBy 进行分区 先按照key分组, 按照key的双重hash来选择后面的分区
- rebalance() 方法会将数据流重新平衡，将数据均匀地分配到所有的分区中，适用于数据倾斜的场景。
- rescale() 方法会将数据流按照哈希值进行分区，但是分区的数量不变，适用于数据均匀分布的场景。
- shuffle() 方法会将数据流随机打乱，然后按照哈希值进行分区，适用于需要随机化数据分布的场景。
- forward() 方法会将数据流发送到下游算子的并行子任务中，适用于数据流只需要在同一个算子中进行处理的场景。

### flink中的sink如何理解？

- 作为数据的输出位置
- sink其本质也就是sinkFunction stream.addSink(sinkFunction);
- 一些内置的sink：![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202304271140162.png)
- 自定义sink [TestSink.java](src%2Ftest%2Fjava%2Forg%2Fexample%2Ftool%2FTestSink.java)，主要是实现invoke函数
- 自定义sinker：kafkaSink [KafkaSinkTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FKafkaSinkTest.java)
- 自定义sinker：redisSink [RedisSinkTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FRedisSinkTest.java)
- 自定义sinker：ElasticsearchSink [ElasticsearchSinkTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FElasticsearchSinkTest.java)
- 自定义sinker：自己封装的 使用jdbc的写入到MySQL的[MySinkFunction.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FSinkFunctionLearn%2FMySinkFunction.java)
- 自定义sinker：自己封装的使用 druid连接池管理jdbc连接的版本[MySinkFunctionWithPool.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FSinkFunctionLearn%2FMySinkFunctionWithPool.java)
- 自定义WALsinker ：自己封装的实现WAL机制的sinker [StdOutWriteAheadSink.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fstreaming_with_flink%2Fchapter8%2FStdOutWriteAheadSink.java)
- 自定义2pcsinker：

需要区分：
- 是否是rich 版本
  - rich版本
  - 非rich版本
- 只实现以上两者并不具有任何的故障恢复能力，这种sink的状态中不含有数据：
  - 如果上游不缺失的话，那么数据都会被处理一次，sinker端往外写出一次
  - 如果发生了故障，那么数据在sinker的结果中要看source端是不是可重置：
    - 不可重置的话从源头就丢了
    - 可重置的话就是恢复，source没丢，然后sinker写出多次。这个时候需要区分下游应用：
      - 如果是类似socket的话，只能追加，那么不能实现端到端的一致性，
      - 如果按照mysql中的主键进行更新，按照hbase的rowkey进行更新，就达到了简单利用sinkFunction接口（未使用状态）
        实现幂等性的sinker实现端到端的一致性，只不过存在一定的时延
- 如果在sinker端加上状态的话，让数据先写入状态的话 即WAL：
  GenericwriteAheadSink这个是WAL的实现，暂存sink算子检查点之间的数据，存入到检查点内，
  然后检查点完成时候把所有数据都写出到外部系统，所以看数据是先被缓存，然后马上又被写出。
  数据是类似波峰的效果的写入到外部，这里的外部可以是任何的一个外部系统，这个机制保证了流入到sinker的数据不会丢失（不会因为写出而丢失），
  但是下游能不能实现类似幂等效果未知。[StdOutWriteAheadSink.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fstreaming_with_flink%2Fchapter8%2FStdOutWriteAheadSink.java)
- 如果下游进一步的支持事务的话：
  - TwoPhaseCommitSinkFunction不会在Flink 的应用状态中收集记录， 而是会把它们写人外部数据汇系统某个开启的事务中，
     第一个记录开启事务，然后其他的数据追加到这个事务中，投票阶段开始于JM插入checkpoint barrier，
     sinker的实例收到了checkpoint barrier之后自己把状态写入检查点，
     等所有的sink都写了，JB将检查点的完成通知发送，然后sink收到提交指令，进行提交，至此一轮2PC结束。


### 2pc的机制： TODO


### flink中的执行模式？BATCH 和 STREAMING 的区别？
- 在流式api上增加了使用BATCH的模式
- 区分于 STREAMING  模式
- 一个公用的规则就是: 当你处理的数据是有界的就应该使用BATCH执行模式, 因为它更加高效. 当你的数据是无界的, 则必须使用STREAMING 执行模式, 因为只有这种模式才能处理持续的数据流.
- 通过命令配置 `bin/flink run -Dexecution.runtime-mode=BATCH ...`
- 有界数据用STREAMING和BATCH的区别
``` 
STREAMING模式下, 数据是来一条输出一次结果.
BATCH模式下, 数据处理完之后, 一次性输出结果.
```

### 如何理解flink中的window？理解要点 WindowAssigner 最大乱序程度，水印，自己写个WatermarkStrategy WatermarkGenerator
- 无界流中截取一段放在某个bucket中，然后基于这部分的静态数据进行计算
- ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202304271813606.png)
- 窗口分为两类窗口：
  - 基于时间的
  - 基于count的
- 如何确定某条数据放在哪几个窗口呢？ -- WindowAssigner 来定
- 如果确定最大乱序程度呢？最好是也是启动一个任务然后监控着就可
- 场景：5秒一个滚动窗口，最大乱序程度3s 情况下进行计算 
  - ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202304281620863.png)
  - [WaterMarkLearnTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FWaterMarkLearnTest.java)
  - 自定义实现的WaterMark： [WaterMarkLearn](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FWaterMarkLearn)

### 即使定义了WaterMark的最大乱序程度也存在迟到数据？
- 可以把迟到数据放到另外的流中，进行处理

### 使用侧输出流把一个流拆成多个流
- [SideOutStreamTest.java](src%2Ftest%2Fjava%2Forg%2Fexample%2FSideOutStreamTest.java)
- 其实就是定义outTag，然后进行输出,侧输出流的数据格式和主的没啥关系
- [SideOutputs.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fstreaming_with_flink%2Fchapter6%2FSideOutputs.java)

### flink中的状态？计算过程中的状态？
- 各种计算过程中的中间值，或者辅助计算的数据都是状态
- 进一步的涉及到：
  状态管理
  状态划分
  状态恢复
- 状态的分类：  
 ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202305041000913.png)
- 疑问点？ 为啥 ValueState 本是记录每个key的转态的，但是实例都是每个Function中都是存储一个私有的成员变量呢
  - 因为ValueState 本身被算子实例持有，但是在通过value获取的时候是按照key 去get的
- Keyed State很类似于一个分布式的key-value map数据结构，只能用于KeyedStream（keyBy算子处理之后）。  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202305041341998.png)
- key state的示例程序：[CountWindowAverage.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FStateLearn%2FCountWindowAverage.java)
- operator state的实例程序：[MyCountMapper.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FStateLearn%2FMyCountMapper.java)
- [WaterSensorListState.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FStateLearn%2FWaterSensorListState.java)
- [WaterSensorMapStateLearn.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FStateLearn%2FWaterSensorMapStateLearn.java)
- [WaterSensorReducingStateLearn01.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FStateLearn%2FWaterSensorReducingStateLearn01.java)
- [WaterSensorAggregatingStateLearn.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fhelloworld%2FStateLearn%2FWaterSensorAggregatingStateLearn.java)
- ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202305041600452.png)

### 状态管理和状态后端
- 状态分为 内置状态 自定义状态，flink一视同仁，用状态后端来管理他们  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072336961.png)
- 如何清理state:  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072336288.png)
- 状态后端是专门用来维护状态的插件，主要工作有两部分
  - 本地状态管理： subtask内的管理形式是存在jvm的堆内存中
  - 远程状态备份：将subtask内的状态以检查点形式写入远程持久化存储

### flink提供的三种状态后端？
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405090848499.png)  
rocksdb本身是一个key-value的数据库，直接读写本地磁盘的，所以大小不受限制，只存在读写磁盘的瓶颈


注意下他们的状态维护和远端状态备份位置

### 如何配置状态后端呢？
``` 
// 创建并配置所选的状态后端
val stateBackend: StateBackend= ??
// 设置状态后端
env.setStateBackend(stateBackend)

比如：
env.setStateBackend(new MemoryStateBackend());
env.setStateBackend(new FsStateBackend("hdfs://xxx:8020/flink/checkpoints/fs"));
env.setStateBackend(new RocksDBStateBackend("hdfs://xx:8020/flink/checkpoints/rocksdb"));
```

### 如何理解端到端的一致性呢?
端到端的状态一致性也是三个部分的，source，flink内部，sink，水桶来看取最低的；构建端到端的一致性等价于下面的要求：

source端：需要外部源可重设数据的读取位置.目前我们使用的Kafka Source具有这种特性: 读取数据的时候可以指定offset

flink内部：依赖checkpoint机制

sink端：需要保证从故障恢复时，数据不会重复写入外部系统. 有2种实现形式:
a)	幂等（Idempotent）写入
所谓幂等操作，是说一个操作，可以重复执行很多次，但只导致一次结果更改，也就是说，后面再重复执行就不起作用了。
b)	事务性（Transactional）写入
需要构建事务来写入外部系统，构建的事务对应着 checkpoint，等到 checkpoint 真正完成的时候，才把所有对应的结果写入 sink 系统中。对于事务性写入，具体又有两种实现方式：预写日志（WAL）和两阶段提交（2PC）

### 一致性检查点
- 有状态的流式应用 的一致性检查点是在所有任务处理完等量的原始输人后对全部任务状态进行的一个拷贝 。  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405080818190.png)  
  比如图中就是 对一个 1 2 3 4 5 6 … 的数据流分奇数和偶数两个分区计算累计和，图中的一直检查点就是计算完了数据流4这个数据，
  然后输入5时候的状态，奇数流的和是9 偶数流的和是9 ，此时的计算输入是5 ，flink就是把这些信息+subtask图 写入到checkpoint中，并存到非易失的介质中。

### 如何从检查点进行恢复和对于下游的影响是如何的？
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405080819430.png)
应用从检查点恢复以后， 它的内部状态会和生成检查点的时候完全一致。  
然后继续处理，这意味着可能存在某些重复处理，尤其是写入到外部的数据的可能已经写出。

这样的处理方案有两种：
- checkpoint做完才做正式的数据提交，这需要外部的写入系统支持
- 本来就是写入幂等的外部系统，多次写入没啥问题

### flink是如何做checkpoint的？flink中检查点算法？
- https://confucianzuoyuan.github.io/flink-tutorial/book/chapter03-05-03-Flink%E7%9A%84%E6%A3%80%E6%9F%A5%E7%82%B9%E7%AE%97%E6%B3%95.html
- Flink的检查点算法中会用到一类名为检查点分隔符 (checkpoint barrier)的特殊记 录。和水位线类似，这些检查点分隔符会通过数据源算子注人到常规的记录流中。
  相对其他记录，它们在流中的位置无法提前或延后。 为了标识所属的检查点， 
  每个检查点分隔符都会带有一个检查点编号，这样就把 一条数据流从逻辑上分成了 两个部分。所有先于分隔符的记录所引起的状; 态更改都会被包含在分隔符所对 应的检查点之中;
  而所有晚 于分隔符的记录所引起的状态更改都会被纳入之后的检查点中  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405080834674.png)
  主要的点在于算子没接收到完整的上游的各个算子实例的barrier的话，只会缓存已经到来barrier的来源方的数据，直到所有的算子的barrier都到了，然后快照存储。

### 检查点的性能影响？如何降低checkpoint对于数据处理的时延影响？
任务在将其状态存入检查点的过程中，会处于阻塞状态，此时的输人会进人缓冲区。
由于状态可能会很大，而且生成检查点需要把这些数据通过网络写人远程存储系统，该过程可能持续数秒，甚至数分钟。
这对于一些延迟敏感的应用而言时间过久。
按照Flink的设计，是由状态后端负责生成检查点，因此任务的状态的具体拷贝过程完全取决于状态后端的实现。
举例而言，文件系统状态后端和RocksDB状态后端支持异步生成检查点。当检查点生成过程触发时，状态后端会为当前状态创建一个本地拷贝。
在本地拷贝创建完成后，任务就可以继续它的常规处理。后台进程会异步将本地状态快照拷贝到远程存储，然后在完成检查点后通知任务。
异步生成检查点可以有效降低任务恢复数据处理所需等待的时间。除此之外，RocksDB状态后端还支持增量生成检查点，这可以有效降低需要传输的数据量。

我们还可以对分隔符对齐这一步进行调整，以降低检查点算法对处理延迟的影响。
对于那些需要极低延迟且能容忍至少一次状态保障的应用，可以通过配置让Flink在分隔符对齐的过程中不缓冲那些已收到分隔符所对应分区的记录，而是直接处理它们。
待所有的检查点分隔符都到达以后，算子才将状态存人检查点，这时候状态可能会包含一些由本应出现在下一次检查点的记录所引起的改动。
一旦出现故障，这些记录会被重复处理，而这意味着检查点只能提供至少一次而非精确一次的一致性保障。  

![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405080839984.png)

### flink的至少一次语义是如何实现的？是如何保证数据一致性的呢？
按照checkpoint barrier 来实现的，如果处理的算子等待上游所有输入的对应的barrier 的话，那么是精准一次性  
如果不等的话，其实就是上游的来了就处理，那么出现回放的话就会重复消费，这是保证了至少一次性  
如果不开chekpoint的话，是最多一次，但是不开的话，kafka可能提交不上offset  

![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405080841517.png)

### flink中的四种图 graph TODO
1. 我们编写的程序是stream graph
2. 提交给到jb时候client转为了

### flink中的data flow
1. 这个是我们编写的程序图
2. 物理的data-flow图
3. 数据并行和任务并行的关系
   4. 数据被拆分为子集 这就是数据并行
   5. 不同的数据分片上的任务，是不同的算子的多个实例 这是任务并行的体现

### 任务实例之间subtasks之间是交换数据的方式有哪些？
逻辑上有 转发，广播，基于键值，随机  
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405062331365.png)

### 数据流上的操作分类
1. 转化操作
> ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405062333936.png)
2. 滚动操作： 这里展示一个算子实例下是如何随着时间更新最小值的
> ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405062334915.png)
3. 窗口操作
> 如何理解窗口呢？  
> 窗口的本质是'桶'作为数据的缓冲，然后在缓冲了的数据上面计算出结果并将数据输出，桶的内容都是有限的，需要进步一的解决，何时创建桶，时间如何分配到具体的桶，桶内的数据如何什么时间参与运算，参与啥样的计算

窗口有哪些分类呢？窗口的分类
- 滚动窗口
  - ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405062338957.png)
- 滑动窗口
  - ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405062339212.png)
- 会话窗口
  - ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405062339842.png)
- 并行滚动窗口
  - 上面的例子都是未进行过分组的，下面的按照颜色进行分组然后滚动窗口
  - ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405062339652.png)

### 如何定义各种窗口？内置窗口分配器？
- 滚动窗口：可以是基于事件时间，也可是基于处理时间
```
        DataStream<Tuple3<Long, Long, Float>> hourlyTips =
                fares.keyBy((TaxiFare fare) -> fare.driverId)
                        .window(TumblingEventTimeWindows.of(Time.hours(1)))
                        .process(new AddTips());
```
- 滑动窗口：
```
        DataStream<Tuple3<Long, Long, Float>> hourlyTips =
                fares.keyBy((TaxiFare fare) -> fare.driverId)
                        .window(SlidingEventTimeWindows.of(Time.hours(1),Time.minutes(15)))
                        .process(new AddTips());
```
- 会话窗口：
```
        DataStream<Tuple3<Long, Long, Float>> hourlyTips =
                fares.keyBy((TaxiFare fare) -> fare.driverId)
                        .window(ProcessingTimeSessionWindows.of(Time.hours(1)))
                        .process(new AddTips());
```

### flink中的时间语义&配置环境中的时间特性：
- 处理时间
- 事件时间：这个必须要求数据中自己带着时间信息
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072233101.png)

```
// 在应用中使用事件时间 
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime); // 这个其实是默认的
```

### 在计算中的算子如何感知计算中的时间进度呢？
--WaterMark  水位线
如何感知窗口的数据都齐了可以进行计算了呢？也是WaterMark，水位线是全局进度指标，表示不会再有比这个时间在晚的数据来到了；当然这是为了告知计算，而非真正的没有后来的数据了

水位线的作用在于平衡延迟和计算的完整性

### 水位线的特性？什么是水位线？
- 事件时间下，用于计算中感知事件时间的进度，整体计算的触发等，这个精度可以调整为微秒，水位线本质也是一种event记录  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072328799.png)
- 水位线必须要单调递增
- 水位线X表示所有小于X的事件都已经到达，比如例子中的5，前面有3 和 5  
  水位线X之后还有比X更小的时间到达，这种事件被称为迟到事件

### 水位线是如何出发窗口的计算的呢？窗口分配器和窗口计算的触发
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405090840084.png)  
- 窗口分配器windowAssigner就是把具体的event放到指定的bucket中
- 触发器：每天调用触发器都会生成一个TriggerResult，用来决定窗口的接下来的行为，如果是fire的话就执行窗口中的函数  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405090839467.png)
- 移除器是一个可选的租组件 Evictor，执行的前后把数据从窗口中删除
- 窗口算子会为每个活动窗口注册一个计时器，等到水位线到了之后就触发Fire  


### flink中的水位线的种类，水位线的分类

![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405080852632.png)

1. 周期性水位线生成器：系统会按照固定的机器时间间隔发出水位线来推动事件时间前进，默认间隔200ms,ExecutionConfig.setAutoWatermarkInterval()可以配置
   按照这个时间间隔，调用AssignerwithPeriodicWatermarks中的getCurrentWatermark()方法。
   如果该方法的返回值非空，且它的时间戳大于上一个水位线的时间戳，那么算子就会发出一个新的水位线。  
   [MyWaterMarkGeneratorForWaterSersor.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2FWaterMarkLearn%2FMyWaterMarkGeneratorForWaterSersor.java)  
   [WaterMarkLearn01.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2FWaterMarkLearn%2FWaterMarkLearn01.java)
2. 定点水位线生成器：
   不是很常用，按事件的特征来产出watermark
   [WaterMarkLearn03.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fflink_training%2FWaterMarkLearn%2FWaterMarkLearn03.java)



### 水位线是如何在多个算子之间传输的？
- 基础场景是 一个subtask中有多个分区，这个subtask需要为这些所有的分区每个都维护一个分区的水位线  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072332894.png)  
  例如上图的某个时刻，subtask维护了4个分区的每个分区的水位线，可以看到这个subtask的下游有三个subtask。随着时间推移如果所有分区中的min(分区水位线)发生了变化就广播到所有的下游subtask
- 这种算法的缺点：  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405072334561.png)

### flink处理迟到数据？
- 直接丢弃
- 重定向到侧数据流
- 基于迟到数据更新结果
- [LateDataHandling.java](src%2Fmain%2Fjava%2Forg%2Fexample%2Fstreaming_with_flink%2Fchapter6%2FLateDataHandling.java)

### flink中的任务故障处理？结果保证？
一个算子实例的基本操作：  
1.接收事件并将它们存在本地缓冲区;  
2.选择性地更新内部状态;  
3.产生输出记录。

上面的每个步骤都可能存在故障， 如果故障发生，事件是否会丟失?如果在更新内部状态后发生故障，系统 恢复后是否会重复更新?在上述情况下，结果是否确定?

由此对应有三种结果保障程度：
- 至多一次
- 至少一次
- 准确一次
- 端到端的精准一次

### flink检查点的制作过程（简化版）：
第一步: Checkpoint Coordinator 向所有 source 节点 trigger Checkpoint. 然后Source Task会在数据流中安插CheckPoint barrier  
第二步: source 节点向下游广播 barrier，这个 barrier 就是实现 Chandy-Lamport 分布式快照算法的核心，下游的 task 只有收到所有进来的 barrier 才会执行相应的 Checkpoint(barrier对齐, 但是新版本有一种新的: barrier)  
第三步: 当 task 完成 state checkpoint后，会将备份数据的地址（state handle）通知给 Checkpoint coordinator。

### flink保存点
Flink的故障恢复算法是基于状态的检查点来完成的。
检查点会周期性地生成，而且会根据配置的策略自动丟弃。
检查点的目的是保证应用在出现故障的时可以顺利重启，因此当应用被手动停止后，检查点也会随之删除。但除了用于故障恢复，应用的一致性快照还有很多其他用途。

Flink最具价值且独具一格的功能之一是保存点。原则上，保存点的生成算法和检查点完全一样，因此可以把保存点看做包含一些额外元数据的检查点。
保存点的生成不是由Flink自动完成，而是需要由用户(或外部调度器)显式触发。同时，Flink也不会自动清理保存点。

有了保存点的话，可以从保存点开始启动任务，这样就可以启动兼容的任务。
- 修复bug
- 提高并行度或者降低并行度，实现应用的扩容和缩容
- 任务迁移到其他计算中心

### flink从保存点启动的一些要求（如何做到启动前后的兼容）？
- flink按照自己的默认算子编号，然后去默认的加载对应的算子状态，但是这样的话，我们的计算图就只能做有限的变动，所以最好是自己给算子分配算子的标志
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405080844374.png)

### flink中的分发转换操作？将数据切分，交给位于不同物理节点上的Task计算？分区算子
- flink中的数据交换策略有多种，说的是任务实例之间的数据发送方向，上游的subtask如何把数据给到下游去？给到哪个下游去？  
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405080846885.png)
- flink为此提供了多种分区算子
  ![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405080846829.png)
  - ShufflePartitioner
  - RebalancePartitioner
  - RescalePartitioner
  - BroadcastPartitioner
  - GlobalPartitioner
  - KeyGroupStreamPartitioner

### flink中设置并行度
即每个算子的实例数，默认来说是执行环境evn中的默认的，如果需要特殊执行某个算子的并行度的话
```
1.设置环境的并行度
env.setParallelism(32)
2.valdefaultP=env.getParallelism
//数据源以默认井行度运行
valresult:=env.addSource(newCustomSource)
//设置map的并行度为默认并行度的两倍
.map(newMyMapper).setParallelism(defaultP*2)
//print数据汇的并行度固定为2
.print().setParallelism(2)
```

### flink中的rich和非rich版本的函数区别？
- 在于是不是有open 和 close的操作

### flink中如何依赖第三方jar？
- 打包时候打一个胖jar
- 依赖放在lib下
- 推荐使用胖jar的方式

### flink确保应用的可维护性？
可维护性体现在：
1. 修复bug，调整功能
2. 增加程序的并行度
3. 迁移新的代码版本

在job最开始运行的时候就指定好算子的唯一标志和整个job的最大的并行度，其中的这个算子的最大并行度可以在env中设置，也可以在算子中单独设置，生效规则如下：  
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405090844004.png)

为算子设置唯一的标志：  
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405090845852.png)  
因为状态中存储了算子的标志，一个状态中需要包含所有的算子的状态，需要按照算子的标志去获取检查点或者保存点中的算子状态


### 如何更新有状态应用？
前提是：  
- 算子唯一标志
- 最大的并行度  
这些是为长期升级等做的准备

更新有状态应用的三个情况：  
1. 保持现有状态更新应用  
2. 从应用中删除状态   
3. 修改算子的状态  

### 设置flink中的状态是可查询的？

TODO


### flink中不同的source和sink组合所能实现的端到端的一致性保证程度？
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405090854452.png)

说明如下：（注意是端到端的）
- 不可重置的数据源在源头时候就可能丢失，所以内部的机制+任何的sink都只能做到最多处理一次
- 可重置的数据源，保证了source端不会丢，但是可能重复，加之内部的机制，如果是任意的数据sink(比如最低socket这种)那么只能实现至少一次，
  搭配幂等性的（比如mysql的jdbc 中upsert的操作）可以实现精确一次性，但是在故障恢复source重置的时候会有临时的不一致，
  而对于可重置source+WAL只能实现至少一次，因为数据可能会因为sinker故障恢复导致多次被发送，但是下游不一定是类似幂等的效果。
  可重置source+2pcsinker可以实现精确一次性的。



### flink读写外部系统：如何实现端到端的一致性？
从上面知道，进一步实现端到端的准确一次性消费，有两种方式，可重置数据源+（幂等性写 or 2PC）
1. 幂等性写：这种的是多次的写入都等同于一次写入，所以重复执行不会引起结果错误，但是追加写入不是幂等的；
   比如：如果下游是一个key-value结果，那么必须保证每次都是写一个key，此外还存在一段时间的结果不正常。
2. 事务写：主要的思想是检查点成功了，才会把成功检查点的结果commit到外部数据系统，这会造成一定的时延，因为结果只有在检查点完成后才会对外可见，而且事务的开销比较大  
注意这里的WAL不能保证写入到下游的端到端的一致性。

### flink写出到下游WAL sinker
WAL数据汇会将所有结果记录写人应用状态，并在收到检查点完成通知后将它们发送到数据汇系统。
由于该数据汇利用状态后端缓冲记录，所以它适用于任意数据汇系统。
然而，WAL数据汇无法100%提供精确一次保障，此外还会导致应用状态大小增加以及接收系统需要处理一次次的“波蜂式〞写入。

- 为啥WAL无法提供100%精确一次性呢？  
  因为数据是放在缓冲区内，然后调用sendValue，这里的数据重复处理来自sinker的状态中，即检查点中，如何发生了故障，数据是被多次发送了的，但是下游不一定得到类似幂等性的结果

### 2PC
2pc需要外部数据支持事务或者是模拟事务，
每次生成检查点都会开启下游的事务，
数据被追加到这次事务中，但是不提交，
直到收到检查点完成的消息，才提交事务，真正写入。
这种写入对比WAL来说是平滑的，不存在波峰式写入。


### flink运维命令
```
flink列出正在运行的app
flink list -r 
```

```
flink为正在运行app生成savepoint
flink savepoint <JobID> [savePath] 
```

```
flink删除savepoint，因为flink不会自动清理这些savepoint
flink savepoint -d [savePath] 
```


```
flink取消job
flink cancel <JobID>
```

```
flink取消job之前同时生成一个savepoint
flink cancel -s [savePath] <JobID>
```


```
flink从保存点启动应用
./bin/flink run -s ‹savepointPath> [options] <jobJar> [arguments]
需要注意savepoint的兼容性 TODO
```


```
flink应用的扩容和缩容
如果是StreamExecutionEnvironment环境中的默认的并行度，这种可以分两种情况：  
      启动任务时候通过 -p参数指定新的并行度  
      未指定并行度，完全机器默认并行度  
这两种情况 可以这样修改 ./bin/fink modify <jobId> -p <newParalelism>  这会产出一个savaPoint，停止job，重新启动
如果是编码中指定的，那么得从新编码打包
```

### flink支持restful api 操作
- 集群的基本信息 ` curl -x GET http://localhost:8081/v1/overview` 注意版本变更

TODO


### flink读取kafka内容规定从何处开始读取？
![](https://raw.githubusercontent.com/getyou123/git_pic_use/master/zz202405192316257.png)

支持指定的时间戳，支持按照map来指定


### flink写入到kafka的端到端的一致性判定？
- flink检查点处于开启状态
- kafka的事务开启状态
- kafka集群配置信息

### 调整检查点参数
启用检查点：
```
val env: StreamExecutionEnvironment = ???
// 启用10秒间隔的检查点 
env.enableCheckpointing(10000);
```

默认情况下：flink内部设置为通过检查点保证精准一次性，如果需要可以自己改为 至少一次性
```
// 从StreamExecutionEnvironment 中 取CheckpointConfig 
val cpConfig: CheckpointConfig = env.getCheckpointConfig
// 设置为至少一次模式
cpConfig. setCheckpointingMode(CheckpointingMode.AT_LEAST_ONCE);
```